{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'version' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m version(sqlalchemy)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'version' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SQLAlchemy==1.4.45\n",
      "  Downloading SQLAlchemy-1.4.45-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\hi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy==1.4.45) (2.0.2)\n",
      "Installing collected packages: SQLAlchemy\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 1.4.47\n",
      "    Uninstalling SQLAlchemy-1.4.47:\n",
      "      Successfully uninstalled SQLAlchemy-1.4.47\n",
      "Successfully installed SQLAlchemy-1.4.45\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install SQLAlchemy==1.4.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(database=\"mlopsDivar\",\n",
    "                        host=\"localhost\",\n",
    "                        user=\"postgres\",\n",
    "                        password=\"alba024024\",\n",
    "                        port=\"5432\")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "engine = create_engine('postgresql://postgres:alba024024@localhost:5432/mlopsDivar')\n",
    "\n",
    "df = pd.read_sql_query('select * from \"pcaBert\"',con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pcaBert0</th>\n",
       "      <th>pcaBert1</th>\n",
       "      <th>pcaBert2</th>\n",
       "      <th>pcaBert3</th>\n",
       "      <th>pcaBert4</th>\n",
       "      <th>pcaBert5</th>\n",
       "      <th>pcaBert6</th>\n",
       "      <th>pcaBert7</th>\n",
       "      <th>pcaBert8</th>\n",
       "      <th>pcaBert9</th>\n",
       "      <th>...</th>\n",
       "      <th>pcaBert40</th>\n",
       "      <th>pcaBert41</th>\n",
       "      <th>pcaBert42</th>\n",
       "      <th>pcaBert43</th>\n",
       "      <th>pcaBert44</th>\n",
       "      <th>pcaBert45</th>\n",
       "      <th>pcaBert46</th>\n",
       "      <th>pcaBert47</th>\n",
       "      <th>pcaBert48</th>\n",
       "      <th>pcaBert49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.441333</td>\n",
       "      <td>-1.126204</td>\n",
       "      <td>4.734657</td>\n",
       "      <td>5.435955</td>\n",
       "      <td>7.477234</td>\n",
       "      <td>0.258758</td>\n",
       "      <td>-0.396307</td>\n",
       "      <td>-0.314401</td>\n",
       "      <td>0.182482</td>\n",
       "      <td>-1.213680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693110</td>\n",
       "      <td>-0.631985</td>\n",
       "      <td>-0.292264</td>\n",
       "      <td>-0.458690</td>\n",
       "      <td>-0.020253</td>\n",
       "      <td>0.089070</td>\n",
       "      <td>0.129138</td>\n",
       "      <td>1.126033</td>\n",
       "      <td>-0.311810</td>\n",
       "      <td>0.436040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.116417</td>\n",
       "      <td>0.322936</td>\n",
       "      <td>4.819297</td>\n",
       "      <td>0.028843</td>\n",
       "      <td>-0.476488</td>\n",
       "      <td>-1.558941</td>\n",
       "      <td>0.602161</td>\n",
       "      <td>-3.448121</td>\n",
       "      <td>0.294073</td>\n",
       "      <td>-3.117329</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064698</td>\n",
       "      <td>0.934524</td>\n",
       "      <td>-1.033687</td>\n",
       "      <td>0.475335</td>\n",
       "      <td>0.957007</td>\n",
       "      <td>0.618454</td>\n",
       "      <td>0.679666</td>\n",
       "      <td>1.131277</td>\n",
       "      <td>-1.205106</td>\n",
       "      <td>-0.382709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.351394</td>\n",
       "      <td>-2.073259</td>\n",
       "      <td>-5.911832</td>\n",
       "      <td>-3.232772</td>\n",
       "      <td>3.745294</td>\n",
       "      <td>0.546827</td>\n",
       "      <td>5.192791</td>\n",
       "      <td>-0.952142</td>\n",
       "      <td>1.883575</td>\n",
       "      <td>-0.373815</td>\n",
       "      <td>...</td>\n",
       "      <td>1.075454</td>\n",
       "      <td>-1.067880</td>\n",
       "      <td>-0.278872</td>\n",
       "      <td>-0.912598</td>\n",
       "      <td>1.153445</td>\n",
       "      <td>0.624537</td>\n",
       "      <td>1.182471</td>\n",
       "      <td>-0.042791</td>\n",
       "      <td>-0.398267</td>\n",
       "      <td>0.785779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.303842</td>\n",
       "      <td>-8.136064</td>\n",
       "      <td>0.449881</td>\n",
       "      <td>-0.252499</td>\n",
       "      <td>0.621241</td>\n",
       "      <td>0.321305</td>\n",
       "      <td>-2.249315</td>\n",
       "      <td>-0.006356</td>\n",
       "      <td>2.849006</td>\n",
       "      <td>-0.433499</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.446891</td>\n",
       "      <td>-0.436919</td>\n",
       "      <td>1.420543</td>\n",
       "      <td>0.129044</td>\n",
       "      <td>-0.356199</td>\n",
       "      <td>0.567443</td>\n",
       "      <td>0.446513</td>\n",
       "      <td>0.204580</td>\n",
       "      <td>1.006669</td>\n",
       "      <td>0.684510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.281825</td>\n",
       "      <td>-0.301084</td>\n",
       "      <td>3.461671</td>\n",
       "      <td>7.153730</td>\n",
       "      <td>-1.813820</td>\n",
       "      <td>-3.709312</td>\n",
       "      <td>-0.710169</td>\n",
       "      <td>4.839833</td>\n",
       "      <td>-0.138675</td>\n",
       "      <td>3.279413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795831</td>\n",
       "      <td>2.290763</td>\n",
       "      <td>0.330745</td>\n",
       "      <td>-1.210905</td>\n",
       "      <td>1.467257</td>\n",
       "      <td>1.165593</td>\n",
       "      <td>-0.083713</td>\n",
       "      <td>-1.478438</td>\n",
       "      <td>-0.614266</td>\n",
       "      <td>0.388161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32723</th>\n",
       "      <td>-3.686972</td>\n",
       "      <td>-4.630200</td>\n",
       "      <td>1.334154</td>\n",
       "      <td>-2.208629</td>\n",
       "      <td>-0.425032</td>\n",
       "      <td>-0.424321</td>\n",
       "      <td>1.030784</td>\n",
       "      <td>1.120464</td>\n",
       "      <td>-5.515956</td>\n",
       "      <td>3.230602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188525</td>\n",
       "      <td>-1.873634</td>\n",
       "      <td>0.116333</td>\n",
       "      <td>0.320174</td>\n",
       "      <td>-1.137829</td>\n",
       "      <td>-0.583138</td>\n",
       "      <td>0.225672</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>2.011259</td>\n",
       "      <td>1.697000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32724</th>\n",
       "      <td>0.729468</td>\n",
       "      <td>1.804447</td>\n",
       "      <td>-2.917272</td>\n",
       "      <td>-0.863680</td>\n",
       "      <td>0.611762</td>\n",
       "      <td>0.373563</td>\n",
       "      <td>5.769012</td>\n",
       "      <td>-0.527323</td>\n",
       "      <td>1.538892</td>\n",
       "      <td>3.170196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340663</td>\n",
       "      <td>0.775186</td>\n",
       "      <td>-0.627113</td>\n",
       "      <td>-0.179035</td>\n",
       "      <td>1.222379</td>\n",
       "      <td>-2.490270</td>\n",
       "      <td>-2.506391</td>\n",
       "      <td>-0.037512</td>\n",
       "      <td>0.337664</td>\n",
       "      <td>-0.911523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32725</th>\n",
       "      <td>0.682478</td>\n",
       "      <td>4.606289</td>\n",
       "      <td>0.546518</td>\n",
       "      <td>-0.975716</td>\n",
       "      <td>0.706939</td>\n",
       "      <td>3.680658</td>\n",
       "      <td>-2.514260</td>\n",
       "      <td>0.319900</td>\n",
       "      <td>-1.416159</td>\n",
       "      <td>-1.144827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285723</td>\n",
       "      <td>0.543390</td>\n",
       "      <td>-0.303502</td>\n",
       "      <td>-0.778179</td>\n",
       "      <td>0.832559</td>\n",
       "      <td>-0.870845</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.327277</td>\n",
       "      <td>-0.048565</td>\n",
       "      <td>0.961620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32726</th>\n",
       "      <td>-0.628269</td>\n",
       "      <td>-4.555729</td>\n",
       "      <td>-1.939719</td>\n",
       "      <td>1.849043</td>\n",
       "      <td>-1.797283</td>\n",
       "      <td>-2.396215</td>\n",
       "      <td>1.242708</td>\n",
       "      <td>-3.772468</td>\n",
       "      <td>2.132668</td>\n",
       "      <td>2.217378</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562550</td>\n",
       "      <td>-0.384942</td>\n",
       "      <td>-0.544598</td>\n",
       "      <td>1.106068</td>\n",
       "      <td>0.388502</td>\n",
       "      <td>0.314327</td>\n",
       "      <td>0.835209</td>\n",
       "      <td>0.071007</td>\n",
       "      <td>-1.216182</td>\n",
       "      <td>-1.277816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32727</th>\n",
       "      <td>2.804802</td>\n",
       "      <td>4.868136</td>\n",
       "      <td>-4.135542</td>\n",
       "      <td>-1.120552</td>\n",
       "      <td>-0.463167</td>\n",
       "      <td>-1.524700</td>\n",
       "      <td>0.440695</td>\n",
       "      <td>-2.367850</td>\n",
       "      <td>-1.977230</td>\n",
       "      <td>-2.592920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477646</td>\n",
       "      <td>-0.590477</td>\n",
       "      <td>-0.270933</td>\n",
       "      <td>0.470694</td>\n",
       "      <td>-1.929969</td>\n",
       "      <td>0.080773</td>\n",
       "      <td>-1.616739</td>\n",
       "      <td>-0.385369</td>\n",
       "      <td>-0.243805</td>\n",
       "      <td>-0.103417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32728 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pcaBert0  pcaBert1  pcaBert2  pcaBert3  pcaBert4  pcaBert5  pcaBert6  \\\n",
       "0      2.441333 -1.126204  4.734657  5.435955  7.477234  0.258758 -0.396307   \n",
       "1     -2.116417  0.322936  4.819297  0.028843 -0.476488 -1.558941  0.602161   \n",
       "2      5.351394 -2.073259 -5.911832 -3.232772  3.745294  0.546827  5.192791   \n",
       "3      6.303842 -8.136064  0.449881 -0.252499  0.621241  0.321305 -2.249315   \n",
       "4     -6.281825 -0.301084  3.461671  7.153730 -1.813820 -3.709312 -0.710169   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "32723 -3.686972 -4.630200  1.334154 -2.208629 -0.425032 -0.424321  1.030784   \n",
       "32724  0.729468  1.804447 -2.917272 -0.863680  0.611762  0.373563  5.769012   \n",
       "32725  0.682478  4.606289  0.546518 -0.975716  0.706939  3.680658 -2.514260   \n",
       "32726 -0.628269 -4.555729 -1.939719  1.849043 -1.797283 -2.396215  1.242708   \n",
       "32727  2.804802  4.868136 -4.135542 -1.120552 -0.463167 -1.524700  0.440695   \n",
       "\n",
       "       pcaBert7  pcaBert8  pcaBert9  ...  pcaBert40  pcaBert41  pcaBert42  \\\n",
       "0     -0.314401  0.182482 -1.213680  ...   0.693110  -0.631985  -0.292264   \n",
       "1     -3.448121  0.294073 -3.117329  ...  -0.064698   0.934524  -1.033687   \n",
       "2     -0.952142  1.883575 -0.373815  ...   1.075454  -1.067880  -0.278872   \n",
       "3     -0.006356  2.849006 -0.433499  ...  -1.446891  -0.436919   1.420543   \n",
       "4      4.839833 -0.138675  3.279413  ...   0.795831   2.290763   0.330745   \n",
       "...         ...       ...       ...  ...        ...        ...        ...   \n",
       "32723  1.120464 -5.515956  3.230602  ...   0.188525  -1.873634   0.116333   \n",
       "32724 -0.527323  1.538892  3.170196  ...   0.340663   0.775186  -0.627113   \n",
       "32725  0.319900 -1.416159 -1.144827  ...   0.285723   0.543390  -0.303502   \n",
       "32726 -3.772468  2.132668  2.217378  ...  -0.562550  -0.384942  -0.544598   \n",
       "32727 -2.367850 -1.977230 -2.592920  ...   0.477646  -0.590477  -0.270933   \n",
       "\n",
       "       pcaBert43  pcaBert44  pcaBert45  pcaBert46  pcaBert47  pcaBert48  \\\n",
       "0      -0.458690  -0.020253   0.089070   0.129138   1.126033  -0.311810   \n",
       "1       0.475335   0.957007   0.618454   0.679666   1.131277  -1.205106   \n",
       "2      -0.912598   1.153445   0.624537   1.182471  -0.042791  -0.398267   \n",
       "3       0.129044  -0.356199   0.567443   0.446513   0.204580   1.006669   \n",
       "4      -1.210905   1.467257   1.165593  -0.083713  -1.478438  -0.614266   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "32723   0.320174  -1.137829  -0.583138   0.225672   0.896861   2.011259   \n",
       "32724  -0.179035   1.222379  -2.490270  -2.506391  -0.037512   0.337664   \n",
       "32725  -0.778179   0.832559  -0.870845  -0.246914  -0.327277  -0.048565   \n",
       "32726   1.106068   0.388502   0.314327   0.835209   0.071007  -1.216182   \n",
       "32727   0.470694  -1.929969   0.080773  -1.616739  -0.385369  -0.243805   \n",
       "\n",
       "       pcaBert49  \n",
       "0       0.436040  \n",
       "1      -0.382709  \n",
       "2       0.785779  \n",
       "3       0.684510  \n",
       "4       0.388161  \n",
       "...          ...  \n",
       "32723   1.697000  \n",
       "32724  -0.911523  \n",
       "32725   0.961620  \n",
       "32726  -1.277816  \n",
       "32727  -0.103417  \n",
       "\n",
       "[32728 rows x 50 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(database=\"mlopsDivar\",\n",
    "                        host=\"localhost\",\n",
    "                        user=\"postgres\",\n",
    "                        password=\"alba024024\",\n",
    "                        port=\"5432\")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "engine = create_engine('postgresql://postgres:alba024024@localhost:5432/mlopsDivar')\n",
    "\n",
    "df2 = pd.read_sql_query('select * from \"PcaLdaDf\"',con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pcaTfIdf0</th>\n",
       "      <th>pcaTfIdf1</th>\n",
       "      <th>pcaTfIdf2</th>\n",
       "      <th>pcaTfIdf3</th>\n",
       "      <th>pcaTfIdf4</th>\n",
       "      <th>pcaTfIdf5</th>\n",
       "      <th>pcaTfIdf6</th>\n",
       "      <th>pcaTfIdf7</th>\n",
       "      <th>pcaTfIdf8</th>\n",
       "      <th>pcaTfIdf9</th>\n",
       "      <th>...</th>\n",
       "      <th>pcaZeroOne15</th>\n",
       "      <th>pcaZeroOne16</th>\n",
       "      <th>pcaZeroOne17</th>\n",
       "      <th>pcaZeroOne18</th>\n",
       "      <th>pcaZeroOne19</th>\n",
       "      <th>LdaZeroOne0</th>\n",
       "      <th>LdaZeroOne1</th>\n",
       "      <th>LdaZeroOne2</th>\n",
       "      <th>LdaZeroOne3</th>\n",
       "      <th>LdaZeroOne4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.044751</td>\n",
       "      <td>0.249483</td>\n",
       "      <td>0.164572</td>\n",
       "      <td>-0.012797</td>\n",
       "      <td>-0.000963</td>\n",
       "      <td>0.035993</td>\n",
       "      <td>0.007848</td>\n",
       "      <td>-0.024350</td>\n",
       "      <td>-0.002302</td>\n",
       "      <td>0.037859</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077669</td>\n",
       "      <td>0.199133</td>\n",
       "      <td>0.673252</td>\n",
       "      <td>0.634965</td>\n",
       "      <td>1.519750</td>\n",
       "      <td>-1.610264</td>\n",
       "      <td>-1.709050</td>\n",
       "      <td>-0.080755</td>\n",
       "      <td>-0.438578</td>\n",
       "      <td>0.338031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.039951</td>\n",
       "      <td>0.010736</td>\n",
       "      <td>-0.070650</td>\n",
       "      <td>-0.048763</td>\n",
       "      <td>-0.013992</td>\n",
       "      <td>-0.021652</td>\n",
       "      <td>-0.021732</td>\n",
       "      <td>-0.066647</td>\n",
       "      <td>0.064906</td>\n",
       "      <td>0.029385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042712</td>\n",
       "      <td>-0.509797</td>\n",
       "      <td>0.166908</td>\n",
       "      <td>-0.156951</td>\n",
       "      <td>-0.042427</td>\n",
       "      <td>-1.610264</td>\n",
       "      <td>-1.709050</td>\n",
       "      <td>-0.080755</td>\n",
       "      <td>-0.438578</td>\n",
       "      <td>0.338031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.046308</td>\n",
       "      <td>0.257797</td>\n",
       "      <td>0.213926</td>\n",
       "      <td>-0.010928</td>\n",
       "      <td>-0.030229</td>\n",
       "      <td>0.057961</td>\n",
       "      <td>-0.097568</td>\n",
       "      <td>0.024358</td>\n",
       "      <td>0.139605</td>\n",
       "      <td>0.294676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008953</td>\n",
       "      <td>0.242515</td>\n",
       "      <td>-0.264961</td>\n",
       "      <td>1.510903</td>\n",
       "      <td>-1.508325</td>\n",
       "      <td>-1.690251</td>\n",
       "      <td>-2.052505</td>\n",
       "      <td>-0.540778</td>\n",
       "      <td>-4.226408</td>\n",
       "      <td>-8.808769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.047306</td>\n",
       "      <td>0.268274</td>\n",
       "      <td>0.213558</td>\n",
       "      <td>0.002980</td>\n",
       "      <td>-0.029782</td>\n",
       "      <td>0.049709</td>\n",
       "      <td>-0.102986</td>\n",
       "      <td>0.006485</td>\n",
       "      <td>0.062538</td>\n",
       "      <td>0.091026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.142871</td>\n",
       "      <td>0.779595</td>\n",
       "      <td>0.417838</td>\n",
       "      <td>-0.226888</td>\n",
       "      <td>1.297839</td>\n",
       "      <td>-1.610264</td>\n",
       "      <td>-1.709050</td>\n",
       "      <td>-0.080755</td>\n",
       "      <td>-0.438578</td>\n",
       "      <td>0.338031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.044211</td>\n",
       "      <td>-0.019987</td>\n",
       "      <td>-0.035861</td>\n",
       "      <td>0.017919</td>\n",
       "      <td>-0.015756</td>\n",
       "      <td>-0.057225</td>\n",
       "      <td>-0.068858</td>\n",
       "      <td>-0.003195</td>\n",
       "      <td>-0.001746</td>\n",
       "      <td>-0.025062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042712</td>\n",
       "      <td>-0.509797</td>\n",
       "      <td>0.166908</td>\n",
       "      <td>-0.156951</td>\n",
       "      <td>-0.042427</td>\n",
       "      <td>-2.263752</td>\n",
       "      <td>9.832432</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.004546</td>\n",
       "      <td>0.004919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32723</th>\n",
       "      <td>-0.036761</td>\n",
       "      <td>-0.008092</td>\n",
       "      <td>-0.013761</td>\n",
       "      <td>0.013496</td>\n",
       "      <td>-0.005785</td>\n",
       "      <td>-0.028639</td>\n",
       "      <td>-0.006102</td>\n",
       "      <td>0.017693</td>\n",
       "      <td>-0.029744</td>\n",
       "      <td>-0.006929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042712</td>\n",
       "      <td>-0.509797</td>\n",
       "      <td>0.166908</td>\n",
       "      <td>-0.156951</td>\n",
       "      <td>-0.042427</td>\n",
       "      <td>-1.653591</td>\n",
       "      <td>-1.895043</td>\n",
       "      <td>-0.328230</td>\n",
       "      <td>-2.408994</td>\n",
       "      <td>-4.384365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32724</th>\n",
       "      <td>-0.036722</td>\n",
       "      <td>-0.014921</td>\n",
       "      <td>-0.016797</td>\n",
       "      <td>0.011278</td>\n",
       "      <td>-0.014591</td>\n",
       "      <td>-0.055900</td>\n",
       "      <td>-0.056586</td>\n",
       "      <td>0.044623</td>\n",
       "      <td>-0.078245</td>\n",
       "      <td>-0.000130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035576</td>\n",
       "      <td>0.297936</td>\n",
       "      <td>-0.289118</td>\n",
       "      <td>-0.088761</td>\n",
       "      <td>-0.036096</td>\n",
       "      <td>-2.466104</td>\n",
       "      <td>13.406247</td>\n",
       "      <td>0.027656</td>\n",
       "      <td>0.141759</td>\n",
       "      <td>-0.098229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32725</th>\n",
       "      <td>-0.029795</td>\n",
       "      <td>-0.025603</td>\n",
       "      <td>-0.015051</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>0.006567</td>\n",
       "      <td>-0.016741</td>\n",
       "      <td>-0.039610</td>\n",
       "      <td>0.011605</td>\n",
       "      <td>-0.042520</td>\n",
       "      <td>0.006723</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040655</td>\n",
       "      <td>-0.040678</td>\n",
       "      <td>-0.195524</td>\n",
       "      <td>0.103424</td>\n",
       "      <td>-0.413869</td>\n",
       "      <td>-1.610264</td>\n",
       "      <td>-1.709050</td>\n",
       "      <td>-0.080755</td>\n",
       "      <td>-0.438578</td>\n",
       "      <td>0.338031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32726</th>\n",
       "      <td>-0.046553</td>\n",
       "      <td>-0.288332</td>\n",
       "      <td>0.291668</td>\n",
       "      <td>-0.009771</td>\n",
       "      <td>-0.217908</td>\n",
       "      <td>0.073740</td>\n",
       "      <td>0.056559</td>\n",
       "      <td>-0.198097</td>\n",
       "      <td>0.309744</td>\n",
       "      <td>-0.309065</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013584</td>\n",
       "      <td>0.183001</td>\n",
       "      <td>0.271467</td>\n",
       "      <td>-0.012745</td>\n",
       "      <td>0.009621</td>\n",
       "      <td>-1.610264</td>\n",
       "      <td>-1.709050</td>\n",
       "      <td>-0.080755</td>\n",
       "      <td>-0.438578</td>\n",
       "      <td>0.338031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32727</th>\n",
       "      <td>-0.038718</td>\n",
       "      <td>-0.008573</td>\n",
       "      <td>-0.039020</td>\n",
       "      <td>-0.012447</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>-0.040344</td>\n",
       "      <td>-0.047139</td>\n",
       "      <td>-0.056888</td>\n",
       "      <td>0.005869</td>\n",
       "      <td>-0.012256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042712</td>\n",
       "      <td>-0.509797</td>\n",
       "      <td>0.166908</td>\n",
       "      <td>-0.156951</td>\n",
       "      <td>-0.042427</td>\n",
       "      <td>-2.382233</td>\n",
       "      <td>11.924981</td>\n",
       "      <td>0.017032</td>\n",
       "      <td>0.084888</td>\n",
       "      <td>-0.055476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32728 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pcaTfIdf0  pcaTfIdf1  pcaTfIdf2  pcaTfIdf3  pcaTfIdf4  pcaTfIdf5  \\\n",
       "0      -0.044751   0.249483   0.164572  -0.012797  -0.000963   0.035993   \n",
       "1      -0.039951   0.010736  -0.070650  -0.048763  -0.013992  -0.021652   \n",
       "2      -0.046308   0.257797   0.213926  -0.010928  -0.030229   0.057961   \n",
       "3      -0.047306   0.268274   0.213558   0.002980  -0.029782   0.049709   \n",
       "4      -0.044211  -0.019987  -0.035861   0.017919  -0.015756  -0.057225   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "32723  -0.036761  -0.008092  -0.013761   0.013496  -0.005785  -0.028639   \n",
       "32724  -0.036722  -0.014921  -0.016797   0.011278  -0.014591  -0.055900   \n",
       "32725  -0.029795  -0.025603  -0.015051   0.005619   0.006567  -0.016741   \n",
       "32726  -0.046553  -0.288332   0.291668  -0.009771  -0.217908   0.073740   \n",
       "32727  -0.038718  -0.008573  -0.039020  -0.012447   0.001695  -0.040344   \n",
       "\n",
       "       pcaTfIdf6  pcaTfIdf7  pcaTfIdf8  pcaTfIdf9  ...  pcaZeroOne15  \\\n",
       "0       0.007848  -0.024350  -0.002302   0.037859  ...     -0.077669   \n",
       "1      -0.021732  -0.066647   0.064906   0.029385  ...      0.042712   \n",
       "2      -0.097568   0.024358   0.139605   0.294676  ...      0.008953   \n",
       "3      -0.102986   0.006485   0.062538   0.091026  ...     -0.142871   \n",
       "4      -0.068858  -0.003195  -0.001746  -0.025062  ...      0.042712   \n",
       "...          ...        ...        ...        ...  ...           ...   \n",
       "32723  -0.006102   0.017693  -0.029744  -0.006929  ...      0.042712   \n",
       "32724  -0.056586   0.044623  -0.078245  -0.000130  ...     -0.035576   \n",
       "32725  -0.039610   0.011605  -0.042520   0.006723  ...     -0.040655   \n",
       "32726   0.056559  -0.198097   0.309744  -0.309065  ...     -0.013584   \n",
       "32727  -0.047139  -0.056888   0.005869  -0.012256  ...      0.042712   \n",
       "\n",
       "       pcaZeroOne16  pcaZeroOne17  pcaZeroOne18  pcaZeroOne19  LdaZeroOne0  \\\n",
       "0          0.199133      0.673252      0.634965      1.519750    -1.610264   \n",
       "1         -0.509797      0.166908     -0.156951     -0.042427    -1.610264   \n",
       "2          0.242515     -0.264961      1.510903     -1.508325    -1.690251   \n",
       "3          0.779595      0.417838     -0.226888      1.297839    -1.610264   \n",
       "4         -0.509797      0.166908     -0.156951     -0.042427    -2.263752   \n",
       "...             ...           ...           ...           ...          ...   \n",
       "32723     -0.509797      0.166908     -0.156951     -0.042427    -1.653591   \n",
       "32724      0.297936     -0.289118     -0.088761     -0.036096    -2.466104   \n",
       "32725     -0.040678     -0.195524      0.103424     -0.413869    -1.610264   \n",
       "32726      0.183001      0.271467     -0.012745      0.009621    -1.610264   \n",
       "32727     -0.509797      0.166908     -0.156951     -0.042427    -2.382233   \n",
       "\n",
       "       LdaZeroOne1  LdaZeroOne2  LdaZeroOne3  LdaZeroOne4  \n",
       "0        -1.709050    -0.080755    -0.438578     0.338031  \n",
       "1        -1.709050    -0.080755    -0.438578     0.338031  \n",
       "2        -2.052505    -0.540778    -4.226408    -8.808769  \n",
       "3        -1.709050    -0.080755    -0.438578     0.338031  \n",
       "4         9.832432     0.002024     0.004546     0.004919  \n",
       "...            ...          ...          ...          ...  \n",
       "32723    -1.895043    -0.328230    -2.408994    -4.384365  \n",
       "32724    13.406247     0.027656     0.141759    -0.098229  \n",
       "32725    -1.709050    -0.080755    -0.438578     0.338031  \n",
       "32726    -1.709050    -0.080755    -0.438578     0.338031  \n",
       "32727    11.924981     0.017032     0.084888    -0.055476  \n",
       "\n",
       "[32728 rows x 105 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAllFeatures = pd.concat([df2 , df] , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), slice(None, 80, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\hi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\hi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\hi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), slice(None, 80, None))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dfAllFeatures[: , :\u001b[39m80\u001b[39;49m]\n",
      "File \u001b[1;32mc:\\Users\\hi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\hi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3804\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m         \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m         \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m         \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3809\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_indexing_error(key)\n\u001b[0;32m   3810\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m \u001b[39m# GH#42269\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5925\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5921\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_indexing_error\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m   5922\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5923\u001b[0m         \u001b[39m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5924\u001b[0m         \u001b[39m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5925\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), slice(None, 80, None))"
     ]
    }
   ],
   "source": [
    "dfAllFeatures[: , :80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"labels\", \"rb\") as fp:   # Unpickling\n",
    "  labels = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , Y_train , Y_test = train_test_split(dfAllFeatures[:80], labels , test_size = 0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8739688359303391\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "classifier = LogisticRegression(max_iter =10000)\n",
    "classifier.fit(X_train , Y_train)\n",
    "Y_pred = classifier.predict(X_test)\n",
    "acc = accuracy_score(Y_test , Y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8464711274060495"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "clf = RidgeClassifier().fit(X_train, Y_train)\n",
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m SVCClf \u001b[39m=\u001b[39m SVC(kernel \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m'\u001b[39m,gamma \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mscale\u001b[39m\u001b[39m'\u001b[39m, shrinking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,)\n\u001b[0;32m      3\u001b[0m SVCClf\u001b[39m.\u001b[39mfit(X_train, Y_train)\n\u001b[1;32m----> 4\u001b[0m Y_pred \u001b[39m=\u001b[39m SVCClf\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[0;32m      5\u001b[0m acc \u001b[39m=\u001b[39m accuracy_score(Y_test , Y_pred)\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(acc)\n",
      "File \u001b[1;32mc:\\Users\\hi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:820\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    818\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecision_function(X), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    819\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[0;32m    821\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39masarray(y, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp))\n",
      "File \u001b[1;32mc:\\Users\\hi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:435\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    433\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_for_predict(X)\n\u001b[0;32m    434\u001b[0m predict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse_predict \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dense_predict\n\u001b[1;32m--> 435\u001b[0m \u001b[39mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[1;32mc:\\Users\\hi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:454\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    446\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    447\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mX.shape[1] = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m should be equal to \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    448\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mthe number of samples at training time\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    449\u001b[0m             \u001b[39m%\u001b[39m (X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape_fit_[\u001b[39m0\u001b[39m])\n\u001b[0;32m    450\u001b[0m         )\n\u001b[0;32m    452\u001b[0m svm_type \u001b[39m=\u001b[39m LIBSVM_IMPL\u001b[39m.\u001b[39mindex(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl)\n\u001b[1;32m--> 454\u001b[0m \u001b[39mreturn\u001b[39;00m libsvm\u001b[39m.\u001b[39;49mpredict(\n\u001b[0;32m    455\u001b[0m     X,\n\u001b[0;32m    456\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msupport_,\n\u001b[0;32m    457\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msupport_vectors_,\n\u001b[0;32m    458\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_n_support,\n\u001b[0;32m    459\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dual_coef_,\n\u001b[0;32m    460\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_intercept_,\n\u001b[0;32m    461\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_probA,\n\u001b[0;32m    462\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_probB,\n\u001b[0;32m    463\u001b[0m     svm_type\u001b[39m=\u001b[39;49msvm_type,\n\u001b[0;32m    464\u001b[0m     kernel\u001b[39m=\u001b[39;49mkernel,\n\u001b[0;32m    465\u001b[0m     degree\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdegree,\n\u001b[0;32m    466\u001b[0m     coef0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoef0,\n\u001b[0;32m    467\u001b[0m     gamma\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gamma,\n\u001b[0;32m    468\u001b[0m     cache_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_size,\n\u001b[0;32m    469\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVCClf = SVC(kernel = 'linear',gamma = 'scale', shrinking = False,)\n",
    "SVCClf.fit(X_train, Y_train)\n",
    "Y_pred = SVCClf.predict(X_test)\n",
    "acc = accuracy_score(Y_test , Y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m SVC_model \u001b[39m=\u001b[39m SVC()\n\u001b[0;32m      2\u001b[0m KNN_model \u001b[39m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m SVC_model\u001b[39m.\u001b[39;49mfit(X_train, Y_train)\n\u001b[0;32m      4\u001b[0m KNN_model\u001b[39m.\u001b[39mfit(X_train, Y_train)\n",
      "File \u001b[1;32mc:\\Users\\hi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:252\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[LibSVM]\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    251\u001b[0m seed \u001b[39m=\u001b[39m rnd\u001b[39m.\u001b[39mrandint(np\u001b[39m.\u001b[39miinfo(\u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mmax)\n\u001b[1;32m--> 252\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[39m=\u001b[39;49mseed)\n\u001b[0;32m    253\u001b[0m \u001b[39m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape_fit_ \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32mc:\\Users\\hi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:331\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    317\u001b[0m libsvm\u001b[39m.\u001b[39mset_verbosity_wrap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m    319\u001b[0m \u001b[39m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[39m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    321\u001b[0m (\n\u001b[0;32m    322\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_,\n\u001b[0;32m    323\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_vectors_,\n\u001b[0;32m    324\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_support,\n\u001b[0;32m    325\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdual_coef_,\n\u001b[0;32m    326\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_,\n\u001b[0;32m    327\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probA,\n\u001b[0;32m    328\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probB,\n\u001b[0;32m    329\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_status_,\n\u001b[0;32m    330\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_iter,\n\u001b[1;32m--> 331\u001b[0m ) \u001b[39m=\u001b[39m libsvm\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    332\u001b[0m     X,\n\u001b[0;32m    333\u001b[0m     y,\n\u001b[0;32m    334\u001b[0m     svm_type\u001b[39m=\u001b[39;49msolver_type,\n\u001b[0;32m    335\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    336\u001b[0m     \u001b[39m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;49;00m\n\u001b[0;32m    337\u001b[0m     class_weight\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m_class_weight\u001b[39;49m\u001b[39m\"\u001b[39;49m, np\u001b[39m.\u001b[39;49mempty(\u001b[39m0\u001b[39;49m)),\n\u001b[0;32m    338\u001b[0m     kernel\u001b[39m=\u001b[39;49mkernel,\n\u001b[0;32m    339\u001b[0m     C\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC,\n\u001b[0;32m    340\u001b[0m     nu\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnu,\n\u001b[0;32m    341\u001b[0m     probability\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprobability,\n\u001b[0;32m    342\u001b[0m     degree\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdegree,\n\u001b[0;32m    343\u001b[0m     shrinking\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshrinking,\n\u001b[0;32m    344\u001b[0m     tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[0;32m    345\u001b[0m     cache_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_size,\n\u001b[0;32m    346\u001b[0m     coef0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoef0,\n\u001b[0;32m    347\u001b[0m     gamma\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gamma,\n\u001b[0;32m    348\u001b[0m     epsilon\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon,\n\u001b[0;32m    349\u001b[0m     max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m    350\u001b[0m     random_seed\u001b[39m=\u001b[39;49mrandom_seed,\n\u001b[0;32m    351\u001b[0m )\n\u001b[0;32m    353\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SVC_model = SVC()\n",
    "KNN_model = KNeighborsClassifier(n_neighbors=5)\n",
    "SVC_model.fit(X_train, Y_train)\n",
    "KNN_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_prediction = SVC_model.predict(X_test)\n",
    "KNN_prediction = KNN_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(SVC_prediction , Y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classify with just zeroAndOne pca LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , Y_train , Y_test = train_test_split( pcaZeroOne , labels , test_size = 0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "classifier = LogisticRegression(max_iter =10000)\n",
    "classifier.fit(X_train , Y_train)\n",
    "Y_pred = classifier.predict(X_test)\n",
    "acc = accuracy_score(Y_test , Y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classify with just Tf-Idf pca LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , Y_train , Y_test = train_test_split( pcaTfIdf , labels , test_size = 0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "classifier = LogisticRegression(max_iter =10000)\n",
    "classifier.fit(X_train , Y_train)\n",
    "Y_pred = classifier.predict(X_test)\n",
    "acc = accuracy_score(Y_test , Y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classify with Tf-Idf and ZeroOne pca LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , Y_train , Y_test = train_test_split( PcaLdaDf, labels , test_size = 0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "classifier = LogisticRegression(max_iter =10000)\n",
    "classifier.fit(X_train , Y_train)\n",
    "Y_pred = classifier.predict(X_test)\n",
    "acc = accuracy_score(Y_test , Y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classify with just ZeroOne LDA LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "classifier = LogisticRegression(max_iter =10000)\n",
    "classifier.fit(featureTrain , Y_train)\n",
    "Y_pred = classifier.predict(featureTest)\n",
    "acc = accuracy_score(Y_test , Y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {}\n",
    "for i in range(len(labels)):\n",
    "  if str(labels[i]) not in categories:\n",
    "    categories[str(labels[i])] = 1\n",
    "  else:\n",
    "    categories[str(labels[i])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
